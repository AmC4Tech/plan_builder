import config from '../config/index.js';
import type { ProjectData } from '../types/index.js';

interface ChatModel {
    invoke(prompt: string): Promise<{ content: string }>;
}

/**
 * AI å†…å®¹ç”Ÿæˆå™¨ - ä½¿ç”¨ LangChain.js ç”Ÿæˆæ–‡æœ¬å†…å®¹
 */
class AIWriter {
    private llm: ChatModel | null = null;
    private initialized = false;

    /**
     * åˆå§‹åŒ– LLM
     */
    async initialize(): Promise<void> {
        if (this.initialized) return;

        if (config.openai.apiKey) {
            // ä½¿ç”¨ OpenAI
            const { ChatOpenAI } = await import('@langchain/openai');
            this.llm = new ChatOpenAI({
                openAIApiKey: config.openai.apiKey,
                modelName: 'gpt-3.5-turbo',
                temperature: 0.7,
            });
            console.log('ğŸ¤– AI Writer: ä½¿ç”¨ OpenAI æ¨¡å¼');
        } else {
            // ä½¿ç”¨ Mock LLM
            console.log('ğŸ¤– AI Writer: ä½¿ç”¨ Mock LLM æ¨¡å¼ï¼ˆæœªé…ç½® OpenAI API Keyï¼‰');
        }

        this.initialized = true;
    }

    /**
     * ç”Ÿæˆå†…å®¹
     * @param prompt - æç¤ºè¯
     * @param context - ä¸Šä¸‹æ–‡æ•°æ®
     * @returns ç”Ÿæˆçš„æ–‡æœ¬
     */
    async generateContent(prompt: string, context: Partial<ProjectData> = {}): Promise<string> {
        await this.initialize();

        // æ„å»ºå®Œæ•´æç¤ºè¯
        const fullPrompt = this.buildPrompt(prompt, context);

        if (this.llm) {
            // ä½¿ç”¨çœŸå® LLM
            try {
                const response = await this.llm.invoke(fullPrompt);
                return response.content;
            } catch (error) {
                const err = error as Error;
                console.error('AI ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨ Mock å›é€€:', err.message);
                return this.mockGenerate(prompt, context);
            }
        } else {
            // ä½¿ç”¨ Mock
            return this.mockGenerate(prompt, context);
        }
    }

    /**
     * æ„å»ºå®Œæ•´æç¤ºè¯
     */
    private buildPrompt(prompt: string, context: Partial<ProjectData>): string {
        let fullPrompt = prompt;

        // æ³¨å…¥ä¸Šä¸‹æ–‡
        if (context.projectName) {
            fullPrompt = fullPrompt.replace('{projectName}', context.projectName);
        }
        if (context.projectDescription) {
            fullPrompt = `é¡¹ç›®èƒŒæ™¯: ${context.projectDescription}\n\n${fullPrompt}`;
        }

        return fullPrompt;
    }

    /**
     * Mock ç”Ÿæˆå™¨ - è¿”å›æ¨¡æ‹Ÿå†…å®¹
     */
    private mockGenerate(prompt: string, context: Partial<ProjectData>): string {
        const projectName = context.projectName || 'ç¤ºä¾‹é¡¹ç›®';

        // æ ¹æ®æç¤ºè¯ç±»å‹è¿”å›ä¸åŒçš„ Mock å†…å®¹
        const mockTemplates: Record<string, string> = {
            'feasibility': `
# å¯è¡Œæ€§åˆ†ææŠ¥å‘Š

## æŠ€æœ¯å¯è¡Œæ€§
${projectName}é¡¹ç›®ä»æŠ€æœ¯è§’åº¦åˆ†æå…·æœ‰è¾ƒé«˜çš„å¯è¡Œæ€§ã€‚å½“å‰å¸‚åœºä¸Šå·²æœ‰æˆç†Ÿçš„æŠ€æœ¯æ–¹æ¡ˆå¯ä¾›å‚è€ƒï¼Œå¼€å‘å›¢é˜Ÿå…·å¤‡ç›¸å…³æŠ€æœ¯ç»éªŒã€‚

## ç»æµå¯è¡Œæ€§
æ ¹æ®åˆæ­¥ä¼°ç®—ï¼Œé¡¹ç›®æŠ•èµ„å›æŠ¥æœŸé¢„è®¡ä¸º18-24ä¸ªæœˆï¼ŒæŠ•èµ„å›æŠ¥ç‡é¢„è®¡å¯è¾¾150%ä»¥ä¸Šã€‚

## è¿è¥å¯è¡Œæ€§
é¡¹ç›®è¿è¥æ¨¡å¼æ¸…æ™°ï¼Œäººå‘˜é…ç½®åˆç†ï¼Œé£é™©å¯æ§ã€‚

## ç»“è®º
ç»¼åˆä»¥ä¸Šåˆ†æï¼Œå»ºè®®ç«‹é¡¹æ¨è¿›ã€‚
      `.trim(),

            'risk': `
# é£é™©åˆ†æ

## æŠ€æœ¯é£é™©
- æ–°æŠ€æœ¯å­¦ä¹ æ›²çº¿å¯èƒ½å½±å“å¼€å‘è¿›åº¦
- ç¬¬ä¸‰æ–¹ä¾èµ–ç¨³å®šæ€§éœ€è¦è¯„ä¼°

## å¸‚åœºé£é™©
- å¸‚åœºéœ€æ±‚å˜åŒ–å¯èƒ½å½±å“äº§å“æ–¹å‘
- ç«äº‰å¯¹æ‰‹åŠ¨æ€éœ€æŒç»­å…³æ³¨

## ç®¡ç†é£é™©
- å›¢é˜Ÿåä½œæ•ˆç‡éœ€è¦ä¿éšœ
- éœ€æ±‚å˜æ›´æ§åˆ¶éœ€è¦åŠ å¼º

## åº”å¯¹æªæ–½
1. å»ºç«‹æŠ€æœ¯é¢„ç ”æœºåˆ¶
2. å®šæœŸå¸‚åœºè°ƒç ”
3. å®Œå–„é¡¹ç›®ç®¡ç†æµç¨‹
      `.trim(),

            'summary': `
# é¡¹ç›®æ¦‚è¿°

${projectName}æ˜¯ä¸€ä¸ªæ—¨åœ¨è§£å†³ç‰¹å®šä¸šåŠ¡é—®é¢˜çš„åˆ›æ–°é¡¹ç›®ã€‚é€šè¿‡é‡‡ç”¨å…ˆè¿›çš„æŠ€æœ¯æ–¹æ¡ˆå’Œç§‘å­¦çš„ç®¡ç†æ–¹æ³•ï¼Œæœ¬é¡¹ç›®å°†ä¸ºç”¨æˆ·æä¾›é«˜æ•ˆã€å¯é çš„è§£å†³æ–¹æ¡ˆã€‚

## é¡¹ç›®ç›®æ ‡
- æé«˜ä¸šåŠ¡æ•ˆç‡30%ä»¥ä¸Š
- é™ä½è¿è¥æˆæœ¬20%
- æå‡ç”¨æˆ·æ»¡æ„åº¦è‡³90%ä»¥ä¸Š

## é¢„æœŸæˆæœ
é¡¹ç›®å®Œæˆåå°†äº¤ä»˜å®Œæ•´çš„ç³»ç»Ÿè§£å†³æ–¹æ¡ˆï¼ŒåŒ…æ‹¬æ ¸å¿ƒåŠŸèƒ½æ¨¡å—ã€é…å¥—æ–‡æ¡£å’ŒåŸ¹è®­ææ–™ã€‚
      `.trim(),
        };

        // åŒ¹é…æ¨¡æ¿
        const promptLower = prompt.toLowerCase();
        if (promptLower.includes('feasibility') || promptLower.includes('å¯è¡Œæ€§')) {
            return mockTemplates.feasibility;
        }
        if (promptLower.includes('risk') || promptLower.includes('é£é™©')) {
            return mockTemplates.risk;
        }
        if (promptLower.includes('summary') || promptLower.includes('æ¦‚è¿°') || promptLower.includes('æ¦‚è¦')) {
            return mockTemplates.summary;
        }

        // é»˜è®¤è¿”å›
        return `[AI ç”Ÿæˆå†…å®¹]\n\né’ˆå¯¹"${prompt.substring(0, 50)}..."çš„åˆ†æå†…å®¹å°†åœ¨æ­¤å¤„å±•ç¤ºã€‚\n\né¡¹ç›®åç§°: ${projectName}\nç”Ÿæˆæ—¶é—´: ${new Date().toLocaleString('zh-CN')}`;
    }

    /**
     * æ‰¹é‡ç”Ÿæˆå†…å®¹
     */
    async generateBatch(
        requests: Array<{ field: string; prompt: string }>,
        context: Partial<ProjectData> = {}
    ): Promise<Record<string, string>> {
        const results: Record<string, string> = {};

        for (const req of requests) {
            results[req.field] = await this.generateContent(req.prompt, context);
        }

        return results;
    }
}

// å¯¼å‡ºå•ä¾‹
export const aiWriter = new AIWriter();
export default aiWriter;
